apiVersion: v1
kind: Service
metadata:
  name: sw
  labels:
    app: sw
spec:
  ports:
  - port: 8081
    name: web-ui
  clusterIP: None
  selector:
    app: sw
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sw
spec:
  serviceName: sw
  replicas: {{ sw_replicas }}
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: sw
  template:
    metadata:
      labels:
        app: sw
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "app"
                    operator: In
                    values:
                    - sw
              topologyKey: "kubernetes.io/hostname"
      containers:
      - name: sw
        imagePullPolicy: Always
        image: dckreg:5000/spark:{{ spark_version }}
        ports:
        - containerPort: 7077
          name: master-port
        - containerPort: 8081
          name: webui-ui
        command:
        - sh
        - -c
        - sh /tmp/spark-configmap/spark-configmap.sh && startspark.sh
        env:
        - name: MODE
          value: "worker"
        - name: SPARK_MASTER_IP
          value: "sm-0.sm"
        - name: SPARK_LOCAL_DIRS
          value: "/data/spark/data"
        - name: SPARK_WORKER_DIR
          value: "/data/spark/work"
        - name: SPARK_MASTER_WEBUI_PORT
          value: "8080"
        - name: SPARK_DAEMON_JAVA_OPTS
          value: "-Dspark.deploy.recoveryMode=FILESYSTEM -Dspark.deploy.recoveryDirectory=/data/spark/recovery"
        - name: ZK_LIST
          value: "{{ zk_list }}"
        - name: KAFKA_BROKER_LIST
          value: "{{ kafka_broker_list }}"
        volumeMounts:
        - name: datadir
          mountPath: /data
        - name: spark-configmap
          mountPath: /tmp/spark-configmap
        - name: spark-env
          mountPath: /tmp/spark-env
        - name: hdfs-site
          mountPath: /tmp/hdfs
        - name: core-site
          mountPath: /tmp/core
      volumes:
        - name: spark-configmap
          configMap:
             name: spark-configmap
             items:
              - key: config
                path: spark-configmap.sh
        - name: spark-env
          configMap:
             name: spark-env
             items:
              - key: config
                path: spark-env.sh
        - name: hdfs-site
          configMap:
             name: hdfs-site
             items:
              - key: config
                path: hdfs-site.xml
        - name: core-site
          configMap:
             name: core-site
             items:
              - key: config
                path: care-site.xml
  volumeClaimTemplates:
  - metadata:
      name: datadir
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: {{ storage_class }}
      resources:
        requests:
          storage: {{ sw_disk }}
